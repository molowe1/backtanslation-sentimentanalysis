{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96654d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b77d3cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour à tous ! J'espère que vous passez une merveilleuse journée ! ☀️ #Bonjour #BonneJournée\n",
      "2. Ce soir, prévu de regarder un film bien au chaud sous la couette. 🍿🎥 #SoiréeFilm #Cocooning\n",
      "3. Aujourd'hui est une journée gourmande ! Le gâteau au chocolat est divin ! 🍰🍫 #Gourmandise #GâteauAuChocolat\n",
      "4. Le temps automnal me donne envie d'une promenade dans la forêt. 🍂🍁 #Automne #Promenade\n",
      "5. J'adore les weekends ! Au programme : détente et plaisir. 🎉🛋️ #Weekend #Détente\n",
      "6. Aujourd'hui, je retrouve enfin mes amis. J'ai tellement hâte ! 👭❤️ #Retrouvailles #Amis\n",
      "7. Je suis si reconnaissant(e) pour ma famille. Ils sont toujours là pour moi. ❤️ #Reconnaissance #Famille\n",
      "8. J'ai trouvé un nouveau livre à lire ! J'ai hâte de m'y plonger. 📚🤓 #NouveauLivre #Lecture\n",
      "9. Ce matin, j'ai été témoin d'un magnifique lever de soleil. La nature est superbe ! 🌅🏞️ #LeverDeSoleil #Nature\n",
      "10. Bienvenue aux nouveaux abonnés ! Merci de partager ce voyage avec moi. 🙏🌟 #NouveauxAbonnés #Merci\n",
      "11. C'est l'heure de mettre de la musique et de ranger la maison pour le weekend ! 🎶🧹 #Musique #Ménage\n",
      "12. Merci à tous pour les vœux d'anniversaire ! Je suis touché(e) par tant d'amour. 💕🎂 #Anniversaire #Merci\n",
      "13. La soirée d'automne est si belle, je vais en profiter pour me détendre dehors. 🌌🍂 #SoiréeAutomne #Détente\n",
      "14. Aujourd'hui est une journée de détente. Je vais savourer un bon livre et une tasse de thé. 📖☕ #Détente #Thé\n",
      "15. Dimanche matin tranquille au lit. Je vais rester ici un moment. 😴🛌 #DimancheMatin #Repos\n",
      "16. Je suis prêt(e) pour la nouvelle semaine ! Bon courage à tous pour ce lundi ! 💪🌟 #NouvelleSemaine #Lundi\n",
      "17. Je viens d'acheter une écharpe chaude pour affronter l'hiver. ❄️🧣 #Achat #Hiver\n",
      "18. Ce soir, je vais à une soirée cinéma avec des amis. Quel film choisirons-nous ? 🎬🍿 #SoiréeCinéma #Amis\n",
      "19. Cela fait longtemps que je n'ai pas visité de musée. J'ai hâte de découvrir de nouvelles expositions. 🖼️🤩 #Musée #Exposition\n",
      "20. Un moment gourmand pour l'après-midi - une glace sous le soleil ! 🍦☀️ #PauseGourmande #Glace\n",
      "21. J'ai réussi à faire de grands progrès dans mon projet de travail aujourd'hui. C'est une belle sensation ! 👍💼 #Progrès #Travail\n",
      "22. Les couleurs automnales sont à couper le souffle. J'adore cette saison ! 🍁🍂 #CouleursAutomnales #Saison\n",
      "23. Ce soir, un pique-nique improvisé au parc. J'en profite pleinement. 🍽️🌳 #PiqueNique #Parc\n",
      "24. Félicitations à tous les diplômés ! Beau travail ! 👩‍🎓🎉 #Diplômés #Félicitations\n",
      "25. Les projets sportifs du weekend sont définis - je vais faire du vélo et nager. 🚴‍♀️🏊 #Sport #Weekend\n",
      "26. Aujourd'hui, je pars en randonnée dans un parc national. J'emporte mon appareil photo ! 🏞️📷 #Randonnée #ParcNational\n",
      "27. Le vendredi, c'est le moment de se régaler : bon repas et bons moments en famille. 🍽️👨‍👩‍👧 #Vendredi #RepasFamilial\n",
      "28. J'ai hâte d'être à Noël et de profiter des paysages enneigés de l'hiver. ❄️🎄 #Noël #Hiver\n",
      "29. Les vacances d'automne ont commencé - enfin du temps libre à savourer ! 🍂🍁 #VacancesD'Automne #TempsLibre\n",
      "30. L'amour de la nature se réveille en moi lorsque je me promène dans les sentiers de la forêt. 🌿🐦 #Nature #Forêt\n"
     ]
    }
   ],
   "source": [
    "#open the tweets\n",
    "with open(\"french.txt\", \"r\", encoding=\"utf-8\") as files:\n",
    "    lines = files.readlines()\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0e1a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an empty list\n",
    "french_list = []\n",
    "\n",
    "#Iterate over the txt file\n",
    "for line in lines:\n",
    "    french_list.append(line)\n",
    "    \n",
    "#get into data frame\n",
    "french_df = pd.DataFrame({\"french_comments\":french_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2cbcd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Function to remove numbers and punctuation using regular expressions\n",
    "def remove_numbers_and_punctuation(text):\n",
    "    # Replace all numbers and punctuation with an empty string\n",
    "    cleaned_text = re.sub(r'[0-9!@#$%^&*(),.?\":{}|<>]', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the function to the 'Text' column in the DataFrame\n",
    "french_df['Cleaned_Text'] = french_df[\"french_comments\"].apply(remove_numbers_and_punctuation)\n",
    "\n",
    "#removeemoji\n",
    "import emoji\n",
    "import unicodedata\n",
    "\n",
    "# Function to remove emojis from text\n",
    "def remove_emojis(text):\n",
    "    # Replace emojis with their names using the demojize() function\n",
    "    cleaned_text = emoji.demojize(text)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the function to the 'Text' column in the DataFrame\n",
    "french_df['Cleaned_Text'] = french_df['Cleaned_Text'].apply(remove_emojis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb9177a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello everyone I hope you have a wonderful day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tonight planned to watch a warm movie under th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Today is a gourmet day The chocolate cake is d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fall time makes me want a walk in the forest: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love weekends on the relaxation and pleasure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Today I finally find my friends I can't wait: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I am so grateful to my family they are still t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I found a new book to read I can't wait to imm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This morning I witnessed a magnificent sunrise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Welcome to the new subscribers thank you for s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>It's time to put music and store the house for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Thank you all for the birthday wishes I am tou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The fall evening is so beautiful I will take a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Today is a day of relaxation I will savor a go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sunday morning quiet in bed I will stay here f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I am ready for the new week good luck to all f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I just bought a hot scarf to face winter: Snow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Tonight I go to a cinema evening with friends ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I haven't visited a museum for a long time I c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A gourmet moment for the afternoon - an ice cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I managed to make great progress in my work pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Fall colors are breathtaking I love this seaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Tonight an improvised picnic at the park I tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Congratulations to all graduates beautiful wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The weekend sports projects are defined - I'm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Today I go hiking in a national park I take my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Friday is the time to feast on a good meal and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I can't wait to be at Christmas and enjoy the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Fall holidays started - finally free time to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The love of nature wakes up in me when I walk ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         English_Text\n",
       "0   Hello everyone I hope you have a wonderful day...\n",
       "1   Tonight planned to watch a warm movie under th...\n",
       "2   Today is a gourmet day The chocolate cake is d...\n",
       "3   Fall time makes me want a walk in the forest: ...\n",
       "4   I love weekends on the relaxation and pleasure...\n",
       "5   Today I finally find my friends I can't wait: ...\n",
       "6   I am so grateful to my family they are still t...\n",
       "7   I found a new book to read I can't wait to imm...\n",
       "8   This morning I witnessed a magnificent sunrise...\n",
       "9   Welcome to the new subscribers thank you for s...\n",
       "10  It's time to put music and store the house for...\n",
       "11  Thank you all for the birthday wishes I am tou...\n",
       "12  The fall evening is so beautiful I will take a...\n",
       "13  Today is a day of relaxation I will savor a go...\n",
       "14  Sunday morning quiet in bed I will stay here f...\n",
       "15  I am ready for the new week good luck to all f...\n",
       "16  I just bought a hot scarf to face winter: Snow...\n",
       "17  Tonight I go to a cinema evening with friends ...\n",
       "18  I haven't visited a museum for a long time I c...\n",
       "19  A gourmet moment for the afternoon - an ice cr...\n",
       "20  I managed to make great progress in my work pr...\n",
       "21  Fall colors are breathtaking I love this seaso...\n",
       "22  Tonight an improvised picnic at the park I tak...\n",
       "23  Congratulations to all graduates beautiful wor...\n",
       "24  The weekend sports projects are defined - I'm ...\n",
       "25  Today I go hiking in a national park I take my...\n",
       "26  Friday is the time to feast on a good meal and...\n",
       "27  I can't wait to be at Christmas and enjoy the ...\n",
       "28  Fall holidays started - finally free time to s...\n",
       "29  The love of nature wakes up in me when I walk ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#translate to english\n",
    "from googletrans import Translator\n",
    "import time\n",
    "\n",
    "# Function to translate text from spanish to English with a retry mechanism\n",
    "def translate_to_english(text, max_retry=5, sleep_duration=1.0):\n",
    "    retry_count = 0\n",
    "    translator = Translator()\n",
    "    while retry_count < max_retry:\n",
    "        try:\n",
    "            translated_text = translator.translate(text, src='fr', dest='en').text\n",
    "            return translated_text\n",
    "        except Exception as e:\n",
    "            print(f\"Translation failed. Retrying... ({retry_count + 1}/{max_retry})\")\n",
    "            retry_count += 1\n",
    "            time.sleep(sleep_duration)\n",
    "    print(\"Translation failed after maximum retries.\")\n",
    "    return None\n",
    "\n",
    "# Apply the translation function to the 'French_Text' column in the DataFrame\n",
    "french_df['English_Text'] = french_df['Cleaned_Text'].apply(translate_to_english)\n",
    "\n",
    "french_df.drop(columns=[\"french_comments\", \"Cleaned_Text\"], inplace=True)\n",
    "french_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4338644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\johns\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\johns\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (8.1.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\johns\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk>=3.1->textblob) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# Download the stopwords for English from NLTK\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# to remove english stopwords\n",
    "!pip install textblob\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords # get stopwords from NLTK library\n",
    "from nltk.tokenize import word_tokenize # to create word tokens\n",
    "from nltk.stem import WordNetLemmatizer # to reduce words to orginal form\n",
    "from nltk.corpus import words # Get all words in english language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb4f2f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         English_Text Sentiment\n",
      "0   Hello everyone I hope you have a wonderful day...  Positive\n",
      "1   Tonight planned to watch a warm movie under th...  Positive\n",
      "2   Today is a gourmet day The chocolate cake is d...   Neutral\n",
      "3   Fall time makes me want a walk in the forest: ...   Neutral\n",
      "4   I love weekends on the relaxation and pleasure...  Positive\n",
      "5   Today I finally find my friends I can't wait: ...   Neutral\n",
      "6   I am so grateful to my family they are still t...   Neutral\n",
      "7   I found a new book to read I can't wait to imm...  Positive\n",
      "8   This morning I witnessed a magnificent sunrise...  Positive\n",
      "9   Welcome to the new subscribers thank you for s...  Positive\n",
      "10  It's time to put music and store the house for...   Neutral\n",
      "11  Thank you all for the birthday wishes I am tou...  Positive\n",
      "12  The fall evening is so beautiful I will take a...  Positive\n",
      "13  Today is a day of relaxation I will savor a go...  Positive\n",
      "14  Sunday morning quiet in bed I will stay here f...   Neutral\n",
      "15  I am ready for the new week good luck to all f...  Positive\n",
      "16  I just bought a hot scarf to face winter: Snow...  Positive\n",
      "17  Tonight I go to a cinema evening with friends ...   Neutral\n",
      "18  I haven't visited a museum for a long time I c...  Positive\n",
      "19  A gourmet moment for the afternoon - an ice cr...   Neutral\n",
      "20  I managed to make great progress in my work pr...  Positive\n",
      "21  Fall colors are breathtaking I love this seaso...  Positive\n",
      "22  Tonight an improvised picnic at the park I tak...  Positive\n",
      "23  Congratulations to all graduates beautiful wor...  Positive\n",
      "24  The weekend sports projects are defined - I'm ...   Neutral\n",
      "25  Today I go hiking in a national park I take my...   Neutral\n",
      "26  Friday is the time to feast on a good meal and...  Positive\n",
      "27  I can't wait to be at Christmas and enjoy the ...  Positive\n",
      "28  Fall holidays started - finally free time to s...  Positive\n",
      "29  The love of nature wakes up in me when I walk ...  Positive\n"
     ]
    }
   ],
   "source": [
    "#sentiment analysis\n",
    "# Function to perform sentiment analysis using TextBlob\n",
    "def get_sentiment(text):\n",
    "    if text is not None:  # Check if the value is not None\n",
    "        analysis = TextBlob(text)\n",
    "        polarity = analysis.sentiment.polarity\n",
    "        if polarity > 0:\n",
    "            return 'Positive'\n",
    "        elif polarity < 0:\n",
    "            return 'Negative'\n",
    "        else:\n",
    "            return 'Neutral'\n",
    "    return 'Neutral'  # Return 'Neutral' for None values\n",
    "\n",
    "\n",
    "# Apply the function to the 'Text' column in the DataFrame\n",
    "french_df['Sentiment'] = french_df['English_Text'].apply(get_sentiment)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "french_df = pd.DataFrame(french_df, columns=['English_Text', 'Sentiment'])\n",
    "\n",
    "# See quick results of the Sentiment Analysis in a table format\n",
    "print(french_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4269ef61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "Positive    20\n",
       "Neutral     10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See quick results of the Sentiment Analysis\n",
    "frenchsentiment_stored = french_df['Sentiment'].value_counts()\n",
    "french_df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "249c1a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing back translation and sentiment analysis\n",
    "\n",
    "#drop the sentiment column in the german_df dataframe\n",
    "french_df.drop(columns=[\"Sentiment\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66f86d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>French_Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bonjour à tous, j'espère que vous passez une m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ce soir prévu de regarder un film chaud sous l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aujourd'hui est une journée gastronomique le g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Le temps d'automne me donne envie d'une promen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J'adore les week-ends sur le programme de déte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aujourd'hui, je trouve enfin mes amis, je ne p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Je suis tellement reconnaissant à ma famille q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>J'ai trouvé un nouveau livre à lire, j'ai hâte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ce matin, j'ai été témoin d'un magnifique leve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bienvenue chez les nouveaux abonnés merci d'av...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Il est temps de mettre de la musique et de sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Merci à tous pour les souhaits d'anniversaire ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>La soirée d'automne est si belle que j'en prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Aujourd'hui est une journée de détente, je sav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Le dimanche matin calme au lit je resterai ici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Je suis prêt pour la nouvelle semaine Bonne ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Je viens d'acheter une écharpe chaude pour fai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ce soir, je vais à une soirée de cinéma avec d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Je n'ai pas visité un musée depuis longtemps, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Un moment gastronomique pour l'après-midi - un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>J'ai réussi à faire de grands progrès dans mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Les couleurs d'automne sont à couper le souffl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ce soir, un pique-nique improvisé au parc, je ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Félicitations à tous les diplômés beaux travau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Les projets sportifs du week-end sont définis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Aujourd'hui, je fais de la randonnée dans un p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Vendredi est le moment de se régaler d'un bon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>J'ai hâte d'être à Noël et de profiter des pay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Les vacances d'automne ont commencé - Enfin le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>L'amour de la nature se réveille en moi quand ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   French_Translation\n",
       "0   Bonjour à tous, j'espère que vous passez une m...\n",
       "1   Ce soir prévu de regarder un film chaud sous l...\n",
       "2   Aujourd'hui est une journée gastronomique le g...\n",
       "3   Le temps d'automne me donne envie d'une promen...\n",
       "4   J'adore les week-ends sur le programme de déte...\n",
       "5   Aujourd'hui, je trouve enfin mes amis, je ne p...\n",
       "6   Je suis tellement reconnaissant à ma famille q...\n",
       "7   J'ai trouvé un nouveau livre à lire, j'ai hâte...\n",
       "8   Ce matin, j'ai été témoin d'un magnifique leve...\n",
       "9   Bienvenue chez les nouveaux abonnés merci d'av...\n",
       "10  Il est temps de mettre de la musique et de sto...\n",
       "11  Merci à tous pour les souhaits d'anniversaire ...\n",
       "12  La soirée d'automne est si belle que j'en prof...\n",
       "13  Aujourd'hui est une journée de détente, je sav...\n",
       "14  Le dimanche matin calme au lit je resterai ici...\n",
       "15  Je suis prêt pour la nouvelle semaine Bonne ch...\n",
       "16  Je viens d'acheter une écharpe chaude pour fai...\n",
       "17  Ce soir, je vais à une soirée de cinéma avec d...\n",
       "18  Je n'ai pas visité un musée depuis longtemps, ...\n",
       "19  Un moment gastronomique pour l'après-midi - un...\n",
       "20  J'ai réussi à faire de grands progrès dans mon...\n",
       "21  Les couleurs d'automne sont à couper le souffl...\n",
       "22  Ce soir, un pique-nique improvisé au parc, je ...\n",
       "23  Félicitations à tous les diplômés beaux travau...\n",
       "24  Les projets sportifs du week-end sont définis ...\n",
       "25  Aujourd'hui, je fais de la randonnée dans un p...\n",
       "26  Vendredi est le moment de se régaler d'un bon ...\n",
       "27  J'ai hâte d'être à Noël et de profiter des pay...\n",
       "28  Les vacances d'automne ont commencé - Enfin le...\n",
       "29  L'amour de la nature se réveille en moi quand ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#translate back into french and perform sentiment analysis\n",
    "\n",
    "# Function to translate text from english to french with a retry mechanism\n",
    "def translate_to_french(text, max_retry=5, sleep_duration=1.0):\n",
    "    retry_count = 0\n",
    "    translator = Translator()\n",
    "    while retry_count < max_retry:\n",
    "        try:\n",
    "            translated_text = translator.translate(text, src='en', dest='fr').text\n",
    "            return translated_text\n",
    "        except Exception as e:\n",
    "            print(f\"Translation failed. Retrying... ({retry_count + 1}/{max_retry})\")\n",
    "            retry_count += 1\n",
    "            time.sleep(sleep_duration)\n",
    "    print(\"Translation failed after maximum retries.\")\n",
    "    return None\n",
    "# Apply the translation function to the 'french_Tweet' column in the DataFrame\n",
    "french_df['French_Translation'] = french_df['English_Text'].apply(translate_to_french)\n",
    "\n",
    "\n",
    "# drop DataFrame with English translations\n",
    "french_df.drop(columns=[\"English_Text\"], inplace=True)\n",
    "french_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c86041b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.31.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\johns\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\johns\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\johns\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#to perform sentiment analysis\n",
    "!pip install transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f085446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and model for French sentiment analysis\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fbe605a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.0.1+cu118 with CUDA 1108 (you have 2.0.1+cpu)\n",
      "    Python  3.11.3 (you have 3.11.4)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sentiment     Score\n",
      "0   Positive  0.540816\n",
      "1   Positive  0.307856\n",
      "2   Positive  0.313858\n",
      "3   Positive  0.386552\n",
      "4   Positive  0.465478\n",
      "5   Positive  0.431574\n",
      "6   Positive  0.763481\n",
      "7   Positive  0.314949\n",
      "8   Positive  0.744787\n",
      "9   Positive  0.583507\n",
      "10  Positive  0.456393\n",
      "11  Positive  0.664719\n",
      "12  Positive  0.372038\n",
      "13  Positive  0.352988\n",
      "14  Positive  0.320223\n",
      "15  Positive  0.343338\n",
      "16  Positive  0.323851\n",
      "17  Negative  0.269405\n",
      "18  Negative  0.252331\n",
      "19  Positive  0.414432\n",
      "20  Positive  0.490786\n",
      "21  Positive  0.379723\n",
      "22  Positive  0.329717\n",
      "23  Positive  0.452521\n",
      "24  Positive  0.373027\n",
      "25  Negative  0.286848\n",
      "26  Positive  0.431570\n",
      "27  Positive  0.360648\n",
      "28  Positive  0.365383\n",
      "29  Positive  0.400756\n"
     ]
    }
   ],
   "source": [
    "# Create a sentiment analysis pipeline using the loaded model\n",
    "sentiment_analyzer = pipeline(task=\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# convert dataframe to list and filter out any none values\n",
    "french_tweets = [text for text in french_df['French_Translation'].tolist() if text is not None]\n",
    "\n",
    "# Perform sentiment analysis on the French tweets\n",
    "results = sentiment_analyzer(french_tweets)\n",
    "\n",
    "# Create a list to store the results in a table format\n",
    "sentiment_table = []\n",
    "\n",
    "# Set the threshold for considering a sentiment as positive or negative\n",
    "threshold = 0.3\n",
    "\n",
    "# Process the results and store them in the table\n",
    "for result in results:\n",
    "    score = result[\"score\"]\n",
    "    sentiment = \"Positive\" if score > threshold else \"Negative\"\n",
    "    sentiment_table.append({\"Sentiment\": sentiment, \"Score\": score})\n",
    "\n",
    "# Convert the list to a pandas DataFrame\n",
    "df = pd.DataFrame(sentiment_table)\n",
    "\n",
    "# Print the DataFrame (table)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4246e9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "Positive    20\n",
      "Neutral     10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(frenchsentiment_stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dbcfb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sentiment  Count\n",
      "0  Negative      3\n",
      "1  Positive     27\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Sentiment_Group' and calculate the count of each group\n",
    "summary_df = df.groupby('Sentiment').size().reset_index(name='Count')\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
